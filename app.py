import streamlit as st
from datetime import date
import requests
import re
from pdf_builder import build_quote_pdf

st.set_page_config(page_title="PETSHEALTH PDF Generator", page_icon="ğŸ¾", layout="wide")

PETSHEALTH_TEAM_URL = "https://www.petshealth.gr/petshealt-team"
EUROLIFE_URL = "https://www.eurolife.gr/el-GR/proionta/idiotes/katoikidio/my-happy-pet"
INTERLIFE_URL = "https://www.interlife-programs.gr/asfalisi/eidika-programmata/#petcare"

def clean_text(t: str) -> str:
    t = re.sub(r"<[^>]+>", " ", t)
    t = re.sub(r"\s+", " ", t).strip()
    return t

def extract_highlights(url: str, max_items=10):
    """
    Lightweight extractor: pulls some meaningful text chunks.
    Not perfect scraping, but good enough for 'official highlights' textareas.
    """
    r = requests.get(url, timeout=15, headers={"User-Agent":"Mozilla/5.0"})
    r.raise_for_status()
    html = r.text

    # Grab headings and list items roughly
    raw = re.findall(r"<h1[^>]*>(.*?)</h1>|<h2[^>]*>(.*?)</h2>|<h3[^>]*>(.*?)</h3>|<li[^>]*>(.*?)</li>|<p[^>]*>(.*?)</p>", html, flags=re.I|re.S)
    items = []
    for tup in raw:
        for part in tup:
            if part:
                txt = clean_text(part)
                # filter very short / boilerplate
                if len(txt) >= 35 and not any(b in txt.lower() for b in ["cookie", "privacy", "javascript", "Â©"]):
                    items.append(txt)

    # de-dup while preserving order
    seen = set()
    out = []
    for it in items:
        key = it.lower()
        if key in seen:
            continue
        seen.add(key)
        out.append(it)
        if len(out) >= max_items:
            break
    return out

def lines(txt: str):
    return [x.strip() for x in (txt or "").splitlines() if x.strip()]

# ---------- UI Header ----------
st.markdown(
    """
    <div style="padding:14px 18px;border-radius:14px;background:#111827;color:white;">
      <div style="font-size:22px;font-weight:700;">PETSHEALTH â€“ PDF Quote Auto-Generator</div>
      <div style="opacity:0.85;">Create branded pet insurance quotations in seconds</div>
    </div>
    """,
    unsafe_allow_html=True
)
st.write("")

# ---------- Client / Pet ----------
colA, colB = st.columns(2, gap="large")
with colA:
    st.subheader("Client Details")
    client_name = st.text_input("Client Name", value="")
    client_phone = st.text_input("Phone", value="")
    client_email = st.text_input("Email", value="")

with colB:
    st.subheader("Pet Details")
    pet_name = st.text_input("Pet Name", value="")
    pet_species = st.selectbox("Species", ["Dog", "Cat"], index=0)
    pet_breed = st.text_input("Breed", value="")
    pet_dob = st.text_input("Date of Birth (dd/mm/yyyy)", value="")
    pet_microchip = st.text_input("Microchip ID", value="")

st.divider()

# ---------- Pricing ----------
col1, col2, col3 = st.columns([2, 2, 1], gap="large")
with col1:
    st.subheader("Plan 1 (Insurance)")
    plan_1_name = st.text_input("Plan 1 Name", value="PET CARE PLUS")
    plan_1_provider = st.text_input("Plan 1 Provider", value="INTERLIFE")
    plan_1_price = st.number_input("Plan 1 Annual Premium (â‚¬)", min_value=0.0, value=189.0, step=1.0)

with col2:
    st.subheader("Plan 2 (Network)")
    plan_2_name = st.text_input("Plan 2 Name", value="EUROLIFE My Happy Pet (SAFE PET SYSTEM)")
    plan_2_provider = st.text_input("Plan 2 Provider", value="EUROLIFE")
    plan_2_price = st.number_input("Plan 2 Annual Premium (â‚¬)", min_value=0.0, value=85.0, step=1.0)

with col3:
    st.subheader("Total")
    total_price = plan_1_price + plan_2_price
    st.metric("Total Annual Premium", f"{total_price:.2f} â‚¬")
    quote_date = st.date_input("Quote Date", value=date.today())

st.subheader("Notes / Disclaimer (Page 1)")
notes = st.text_area(
    "Shown in the PDF",
    value="Î¤Î¿ Ï€Î±ÏÏŒÎ½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÎ¯ Î¼Î· Î´ÎµÏƒÎ¼ÎµÏ…Ï„Î¹ÎºÎ® Ï€ÏÎ¿ÏƒÏ†Î¿ÏÎ¬. ÎŸÎ¹ Ï„ÎµÎ»Î¹ÎºÎ¿Î¯ ÏŒÏÎ¿Î¹, Ï€ÏÎ¿Ï‹Ï€Î¿Î¸Î­ÏƒÎµÎ¹Ï‚, ÎµÎ¾Î±Î¹ÏÎ­ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ ÎºÎ±Î»ÏÏˆÎµÎ¹Ï‚ Î¹ÏƒÏ‡ÏÎ¿Ï…Î½ ÏŒÏ€Ï‰Ï‚ Î±Î½Î±Î³ÏÎ¬Ï†Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î± ÎµÏ€Î¯ÏƒÎ·Î¼Î± Î­Î³Î³ÏÎ±Ï†Î± Ï„Ï‰Î½ Î±ÏƒÏ†Î±Î»Î¹ÏƒÏ„Î¹ÎºÏÎ½ ÎµÏ„Î±Î¹ÏÎµÎ¹ÏÎ½.",
    height=80
)

st.divider()
st.subheader("Plan Coverage Descriptions (Page 2)")

left, right = st.columns(2, gap="large")

with left:
    st.markdown("### PET CARE PLUS (INTERLIFE)")
    plan1_limit = st.text_input("Limit (Plan 1)", value="2.000â‚¬ / Î±Î½Î¬ Î­Ï„Î¿Ï‚")
    plan1_area = st.text_input("Geographic Area (Plan 1)", value="Î•Î»Î»Î¬Î´Î±")

    plan1_key_facts_txt = st.text_area(
        "Key Facts (one per line)",
        value="\n".join([
            "Î•Î»ÎµÏÎ¸ÎµÏÎ· ÎµÏ€Î¹Î»Î¿Î³Î® ÎºÏ„Î·Î½Î¹Î¬Ï„ÏÎ¿Ï… ÎºÎ±Î¹ ÎºÎ»Î¹Î½Î¹ÎºÎ®Ï‚",
            "Î‘Ï€Î±Î»Î»Î±Î³Î®: 50â‚¬ Î±Î½Î¬ Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÏŒ (ÏŒÏ€Î¿Ï… ÎµÏ†Î±ÏÎ¼ÏŒÎ¶ÎµÏ„Î±Î¹)",
        ]),
        height=80
    )

    plan1_covers_txt = st.text_area(
        "Covers (one per line)",
        value="\n".join([
            "2.000â‚¬ Î³Î¹Î± Î´Î±Ï€Î¬Î½ÎµÏ‚ Î½Î¿ÏƒÎ·Î»ÎµÎ¯Î±Ï‚ (Ï€ÏÎ¿Ï‹Ï€ÏŒÎ¸ÎµÏƒÎ· Î´Î¹Î±Î½Ï…ÎºÏ„Î­ÏÎµÏ…ÏƒÎ·, max 5 Î´Î¹Î±Î½Ï…ÎºÏ„ÎµÏÎµÏÏƒÎµÎ¹Ï‚)",
            "500â‚¬ Î³Î¹Î± Î¹Î±Ï„ÏÎ¹ÎºÎ­Ï‚ ÎµÏ€Î¹ÏƒÎºÎ­ÏˆÎµÎ¹Ï‚ & Î´Î¹Î±Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ­Ï‚ ÎµÎ¾ÎµÏ„Î¬ÏƒÎµÎ¹Ï‚",
            "Î‘Ï€ÏÎ»ÎµÎ¹Î± Î¶Ï‰Î®Ï‚: Î­Ï‰Ï‚ 250â‚¬ (Î±Ï†Î±Î¹ÏÎ¿ÏÎ½Ï„Î±Î¹ Ï„Ï…Ï‡ÏŒÎ½ Î½Î¿ÏƒÎ¿ÎºÎ¿Î¼ÎµÎ¹Î±ÎºÎ­Ï‚ Î´Î±Ï€Î¬Î½ÎµÏ‚ Î±Ï€ÏŒ Ï„Î¿ ÎºÎµÏ†Î¬Î»Î±Î¹Î¿ Î¸Î±Î½Î¬Ï„Î¿Ï…)",
            "Î‘ÏƒÏ„Î¹ÎºÎ® ÎµÏ…Î¸ÏÎ½Î· ÎºÎ·Î´ÎµÎ¼ÏŒÎ½Î±: 10.000â‚¬ / Î­Ï„Î¿Ï‚ (Î±Ï€Î±Î»Î»Î±Î³Î® 50â‚¬ Î±Î½Î¬ Î±Ï€Î±Î¯Ï„Î·ÏƒÎ·)",
            "ÎÎ¿Î¼Î¹ÎºÎ® Ï€ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î± ÎºÎ·Î´ÎµÎ¼ÏŒÎ½Î±: 5.000â‚¬ (Î±Ï€Î±Î»Î»Î±Î³Î® 50â‚¬ Î±Î½Î¬ Ï€ÎµÏÎ¹ÏƒÏ„Î±Ï„Î¹ÎºÏŒ)",
        ]),
        height=140
    )

    plan1_exclusions_txt = st.text_area(
        "Not Covered (one per line)",
        value="\n".join([
            "Check up",
            "Î•Î¼Î²Î¿Î»Î¹Î±ÏƒÎ¼Î¿Î¯",
            "ÎŸÎ´Î¿Î½Ï„Î¹Î±Ï„ÏÎ¹ÎºÎ­Ï‚ Ï€ÏÎ¬Î¾ÎµÎ¹Ï‚ (Ï€Î»Î·Î½ Î±Ï„ÏÏ‡Î·Î¼Î± ÏŒÏ€Î¿Ï… Ï€ÏÎ¿Î²Î»Î­Ï€ÎµÏ„Î±Î¹)",
            "Î ÏÎ¿Ï‹Ï€Î¬ÏÏ‡Î¿Ï…ÏƒÎµÏ‚ Ï€Î±Î¸Î®ÏƒÎµÎ¹Ï‚",
            "Î£Ï…Î³Î³ÎµÎ½ÎµÎ¯Ï‚ Ï€Î±Î¸Î®ÏƒÎµÎ¹Ï‚",
        ]),
        height=110
    )

    plan1_waiting_txt = st.text_area(
        "Waiting Periods (one per line)",
        value="\n".join([
            "Î‘ÏƒÎ¸Î­Î½ÎµÎ¹Î±: 60 Î·Î¼Î­ÏÎµÏ‚ Î±Ï€ÏŒ Ï„Î·Î½ Î­Î½Î±ÏÎ¾Î·",
            "Î‘Ï€ÏÎ»ÎµÎ¹Î± Î¶Ï‰Î®Ï‚: 180 Î·Î¼Î­ÏÎµÏ‚ Î±Ï€ÏŒ Ï„Î·Î½ Î­Î½Î±ÏÎ¾Î·",
            "Î‘Ï„ÏÏ‡Î·Î¼Î±: Î±Ï€ÏŒ Ï„Î·Î½ Î­Î½Î±ÏÎ¾Î· Ï„Î¿Ï… ÏƒÏ…Î¼Î²Î¿Î»Î±Î¯Î¿Ï…",
        ]),
        height=90
    )

with right:
    st.markdown("### EUROLIFE My Happy Pet (SAFE PET SYSTEM)")
    plan2_limit = st.text_input("Limit (Plan 2)", value="Î‘Ï€ÎµÏÎ¹ÏŒÏÎ¹ÏƒÏ„Î¿ (ÎµÎ½Ï„ÏŒÏ‚ Î´Î¹ÎºÏ„ÏÎ¿Ï…, Î¼Îµ ÏƒÏ…Î¼Î¼ÎµÏ„Î¿Ï‡Î®)")
    plan2_area = st.text_input("Geographic Area (Plan 2)", value="Î‘Ï„Ï„Î¹ÎºÎ® â€“ Î˜ÎµÏƒÏƒÎ±Î»Î¿Î½Î¯ÎºÎ· (ÏƒÏ…Î¼Î²ÎµÎ²Î»Î·Î¼Î­Î½Î¿ Î´Î¯ÎºÏ„Ï…Î¿)")

    plan2_key_facts_txt = st.text_area(
        "Key Facts (one per line)",
        value="\n".join([
            "Î‘Ï€Î¿ÎºÎ»ÎµÎ¹ÏƒÏ„Î¹ÎºÎ¬ ÏƒÏ…Î¼Î²ÎµÎ²Î»Î·Î¼Î­Î½Î¿ Î´Î¯ÎºÏ„Ï…Î¿ ÎºÏ„Î·Î½Î¹Î¬Ï„ÏÏ‰Î½ & ÎºÎ»Î¹Î½Î¹ÎºÏÎ½",
            "Î‘Ï€Î±Î»Î»Î±Î³Î®: 0â‚¬ (Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ Î¼Îµ ÏƒÏ…Î¼Î¼ÎµÏ„Î¿Ï‡Î® Î±Î½Î¬ Ï…Ï€Î·ÏÎµÏƒÎ¯Î±)",
            "ÎÎ¿ÏƒÎ¿ÎºÎ¿Î¼ÎµÎ¹Î±ÎºÎ­Ï‚ Î´Î±Ï€Î¬Î½ÎµÏ‚ & ÎµÎ¾ÎµÏ„Î¬ÏƒÎµÎ¹Ï‚ Î¼Îµ ÎµÎ¹Î´Î¹ÎºÏŒ ÎµÎºÏ€Ï„Ï‰Ï„Î¹ÎºÏŒ Ï„Î¹Î¼Î¿ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿ Î³Î¹Î± Î¼Î­Î»Î·",
        ]),
        height=90
    )

    plan2_covers_txt = st.text_area(
        "Covers (one per line)",
        value="\n".join([
            "ÎÎ¿ÏƒÎ¿ÎºÎ¿Î¼ÎµÎ¹Î±ÎºÎ­Ï‚ Î´Î±Ï€Î¬Î½ÎµÏ‚, Î¹Î±Ï„ÏÎ¹ÎºÎ­Ï‚ ÎµÏ€Î¹ÏƒÎºÎ­ÏˆÎµÎ¹Ï‚ & Î´Î¹Î±Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ­Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Î´Î¹ÎºÏ„ÏÎ¿Ï… Î¼Îµ ÏƒÏ…Î¼Î¼ÎµÏ„Î¿Ï‡Î®",
            "Î•Ï„Î®ÏƒÎ¹Î¿ Check Up Î´Ï‰ÏÎµÎ¬Î½ (Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Kala-azar & Î•ÏÎ»Î¯Ï‡Î¹Î±)",
            "Î•Î¼Î²Î¿Î»Î¹Î±ÏƒÎ¼Î¿Î¯ ÏƒÎµ ÎµÎ¹Î´Î¹ÎºÏŒ Ï€ÏÎ¿ÏƒÏ…Î¼Ï†Ï‰Î½Î·Î¼Î­Î½Î¿ Ï„Î¹Î¼Î¿ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿ (ÎµÎ½Ï„ÏŒÏ‚ Î´Î¹ÎºÏ„ÏÎ¿Ï…)",
            "ÎŸÎ´Î¿Î½Ï„Î¹Î±Ï„ÏÎ¹ÎºÎ­Ï‚ Ï€ÏÎ¬Î¾ÎµÎ¹Ï‚ ÏƒÎµ ÎµÎ¹Î´Î¹ÎºÏŒ Ï€ÏÎ¿ÏƒÏ…Î¼Ï†Ï‰Î½Î·Î¼Î­Î½Î¿ Ï„Î¹Î¼Î¿ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿ (ÎµÎ½Ï„ÏŒÏ‚ Î´Î¹ÎºÏ„ÏÎ¿Ï…)",
            "Î ÏÎ¿Ï‹Ï€Î¬ÏÏ‡Î¿Ï…ÏƒÎµÏ‚ Ï€Î±Î¸Î®ÏƒÎµÎ¹Ï‚: ÎºÎ±Î»ÏÏ€Ï„Î¿Î½Ï„Î±Î¹",
            "Î£Ï…Î³Î³ÎµÎ½ÎµÎ¯Ï‚ Ï€Î±Î¸Î®ÏƒÎµÎ¹Ï‚: ÎºÎ±Î»ÏÏ€Ï„Î¿Î½Ï„Î±Î¹",
        ]),
        height=160
    )

    plan2_exclusions_txt = st.text_area(
        "Not Covered / Limits (one per line)",
        value="\n".join([
            "Î•ÎºÏ„ÏŒÏ‚ Î´Î¹ÎºÏ„ÏÎ¿Ï…: Î´ÎµÎ½ Î¹ÏƒÏ‡ÏÎµÎ¹ ÎºÎ¬Î»Ï…ÏˆÎ·/Ï„Î¹Î¼Î¿ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿Ï‚",
            "Î‘Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ Î·Î»ÎµÎºÏ„ÏÎ¿Î½Î¹ÎºÎ® ÏƒÎ®Î¼Î±Î½ÏƒÎ· (microchip)",
            "Î¦Î¬ÏÎ¼Î±ÎºÎ±: ÏƒÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ ÏŒÏÎ¿Ï…Ï‚/Ï„Î¹Î¼Î¿ÎºÎ±Ï„Î¬Î»Î¿Î³Î¿ Ï€ÏÎ¿Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚",
        ]),
        height=110
    )

    plan2_waiting_txt = st.text_area(
        "Waiting Periods (one per line)",
        value="\n".join([
            "Î‘Ï„ÏÏ‡Î·Î¼Î± Î® Î±ÏƒÎ¸Î­Î½ÎµÎ¹Î±: Î±Ï€ÏŒ Ï„Î·Î½ Î­Î½Î±ÏÎ¾Î· Ï„Î¿Ï… ÏƒÏ…Î¼Î²Î¿Î»Î±Î¯Î¿Ï… (ÏƒÏÎ¼Ï†Ï‰Î½Î± Î¼Îµ ÏŒÏÎ¿Ï…Ï‚ Ï€ÏÎ¿Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚)",
        ]),
        height=80
    )

st.divider()
st.subheader("Enrich Content (optional) â€“ Load official highlights")

if "official_eurolife" not in st.session_state:
    st.session_state.official_eurolife = ""
if "official_interlife" not in st.session_state:
    st.session_state.official_interlife = ""
if "official_bio" not in st.session_state:
    st.session_state.official_bio = ""

btn = st.button("Load official highlights", use_container_width=True)

if btn:
    try:
        eu = extract_highlights(EUROLIFE_URL, max_items=8)
        it = extract_highlights(INTERLIFE_URL, max_items=8)
        bio = extract_highlights(PETSHEALTH_TEAM_URL, max_items=8)

        st.session_state.official_eurolife = "\n".join([f"â€¢ {x}" for x in eu])
        st.session_state.official_interlife = "\n".join([f"â€¢ {x}" for x in it])
        st.session_state.official_bio = "\n".join([x for x in bio])

        st.success("Loaded official highlights. Edit them as you wish before generating PDF.")
    except Exception as e:
        st.error(f"Could not load highlights: {e}")

colx, coly = st.columns(2, gap="large")
with colx:
    official_eurolife = st.text_area("EUROLIFE official highlights (editable)", value=st.session_state.official_eurolife, height=160)
with coly:
    official_interlife = st.text_area("INTERLIFE official highlights (editable)", value=st.session_state.official_interlife, height=160)

about_bio = st.text_area("Your Bio / About (Page 3 â€“ editable)", value=st.session_state.official_bio, height=170)

cii_titles = st.text_area(
    "CII Titles / Credentials (one per line)",
    value="\n".join([
        "Chartered Insurance Institute â€“ (PL4) Introduction to Pet Insurance (Unit achieved: June 2023)",
        "Chartered Insurance Institute â€“ (W01) Award in General Insurance (English) (Unit achieved: March 2025)",
    ]),
    height=90
)

st.write("")
generate = st.button("Generate PDF ğŸ§¾", use_container_width=True)

def bullet_lines(txt: str):
    out = []
    for ln in (txt or "").splitlines():
        ln = ln.strip()
        if not ln:
            continue
        ln = ln.lstrip("â€¢").strip()
        out.append(ln)
    return out

if generate:
    payload = {
        "client_name": client_name,
        "client_phone": client_phone,
        "client_email": client_email,
        "pet_name": pet_name,
        "pet_species": pet_species,
        "pet_breed": pet_breed,
        "pet_dob": pet_dob,
        "pet_microchip": pet_microchip,

        "plan_1_name": plan_1_name,
        "plan_1_provider": plan_1_provider,
        "plan_1_price": f"{plan_1_price:.2f}",

        "plan_2_name": plan_2_name,
        "plan_2_provider": plan_2_provider,
        "plan_2_price": f"{plan_2_price:.2f}",

        "total_price": f"{total_price:.2f} â‚¬",
        "quote_date": quote_date.strftime("%d/%m/%Y"),
        "notes": notes,

        "plan1_limit": plan1_limit,
        "plan1_area": plan1_area,
        "plan1_key_facts": lines(plan1_key_facts_txt),
        "plan1_covers": lines(plan1_covers_txt),
        "plan1_exclusions": lines(plan1_exclusions_txt),
        "plan1_waiting": lines(plan1_waiting_txt),

        "plan2_limit": plan2_limit,
        "plan2_area": plan2_area,
        "plan2_key_facts": lines(plan2_key_facts_txt),
        "plan2_covers": lines(plan2_covers_txt),
        "plan2_exclusions": lines(plan2_exclusions_txt),
        "plan2_waiting": lines(plan2_waiting_txt),

        # Page 3 about
        "about_bio": about_bio,
        "cii_titles": lines(cii_titles),

        # Optional official highlights for page 3
        "official_eurolife": bullet_lines(official_eurolife),
        "official_interlife": bullet_lines(official_interlife),
    }

    pdf_bytes = build_quote_pdf(payload)
    filename = f"PETSHEALTH_Quote_{client_name or 'Client'}_{pet_name or 'Pet'}.pdf".replace(" ", "_")

    st.success("PDF generated!")
    st.download_button(
        "Download PDF",
        data=pdf_bytes,
        file_name=filename,
        mime="application/pdf",
        use_container_width=True
    )